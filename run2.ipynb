{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test import load_data_sparse\n",
    "from SGD import *\n",
    "from ALS import *\n",
    "from surprise_models import *\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(real_labels, predictions):\n",
    "    \"\"\"Calculate RMSE.\"\"\"\n",
    "    return np.linalg.norm(real_labels - predictions) / np.sqrt(len(real_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"data/47b05e70-6076-44e8-96da-2530dc2187de_data_train.csv\"\n",
    "test_name = \"data/sampleSubmission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trainset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_ratings, pd_ratings = load_data_sparse(data_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it into surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr_data = pandas_to_surprise(pd_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Movie  Rating\n",
       "0    43      0       4\n",
       "1    60      0       3\n",
       "2    66      0       4\n",
       "3    71      0       3\n",
       "4    85      0       5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spr_data.df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into test and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(spr_data, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pd_pred = load_data_sparse(test_name, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert it into surprise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pandas_to_surprise(pd_pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0080\n"
     ]
    }
   ],
   "source": [
    "svd_test, svd_final, rmse = surprise_SVD(trainset, testset, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0019\n"
     ]
    }
   ],
   "source": [
    "so_test, so_final, so_rmse = surprise_slopeOne(trainset, testset, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 40  # K in the lecture notes\n",
    "lambda_user = 0.1\n",
    "lambda_film = 0.1\n",
    "stop_criterion = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using ALS...\n"
     ]
    }
   ],
   "source": [
    "als_test, als_final = ALS_CV(trainset, testset, pred, num_features, lambda_user, lambda_film, stop_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_test, sgd_final = matrix_factorization_SGD_CV(trainset, testset, pred, num_features, lambda_user, lambda_film, stop_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,rat = get_testset_indices(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0271070183303297"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_rmse(rat, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_from_prediction(prediction, output_name):\n",
    "\n",
    "    def prediction_transformed(prediction, ids_process):\n",
    "        \"\"\" return the prediction transformed for the submission \"\"\"\n",
    "        y = []\n",
    "        for i in range(len(ids_process)):\n",
    "            row = ids_process[i][0]\n",
    "            col = ids_process[i][1]\n",
    "            y.append(prediction[row - 1, col - 1])\n",
    "        return y\n",
    "\n",
    "    def create_csv_submission(ids, y_pred, name):\n",
    "        \"\"\"\n",
    "        Creates an output file in csv format for submission to kaggle\n",
    "        Arguments: ids (event ids associated with each prediction)\n",
    "                   y_pred (predicted class labels)\n",
    "                   name (string name of .csv output file to be created)\n",
    "        \"\"\"\n",
    "        with open(name, 'w') as csvfile:\n",
    "            fieldnames = ['Id', 'Prediction']\n",
    "            writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for r1, r2 in zip(ids, y_pred):\n",
    "                writer.writerow({'Id': str(r1), 'Prediction': float(r2)})\n",
    "\n",
    "    def round(x):\n",
    "        if (x < 1):\n",
    "            return 1\n",
    "        elif (x > 5):\n",
    "            return 5\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def transform(ids_txt):\n",
    "        \"\"\" split the text index\"\"\"\n",
    "\n",
    "        def deal_line(line):\n",
    "            pos, rating = line.split(',')\n",
    "            return str(pos)\n",
    "\n",
    "        ids = [deal_line(line) for line in ids_txt]\n",
    "        return ids\n",
    "\n",
    "    prediction = np.vectorize(round)(prediction)\n",
    "\n",
    "    DATA_TEST_PATH = 'data/sampleSubmission.csv'\n",
    "\n",
    "    ids_txt = read_txt(DATA_TEST_PATH)[1:]\n",
    "    ids_process = [deal_line(line) for line in ids_txt]\n",
    "\n",
    "    # prediction under the right format\n",
    "    # y = prediction_transformed(prediction, ids_process)\n",
    "    y = np.vectorize(round)(prediction)\n",
    "    \n",
    "    y = np.rint(y)\n",
    "\n",
    "    ids = transform(ids_txt)\n",
    "    OUTPUT_PATH = output_name\n",
    "    create_csv_submission(ids, y, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176952,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission_from_prediction(als_final, 'svdfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
