# EPFL ML Recommender System

This repository contains the code necessary to run a Recommender System for movie ratings for the CS-433 Machine Learning course et EPFL.
The dataset comes from the [crowdAI Platform](https://www.crowdai.org/challenges/epfl-ml-recommender-system) and consist of ratings of 10000 users for 1000 different movies.
We are supposed to predict good recommendations, e.g. of movies to users. All ratings are integer values between 1 and 5 stars.

The code is written in Python and run on Jupyter notebooks

**RMSE on crowdAI: ** 1.016

## Team members

- BARAKAT Arthur
- VEILLARD Jennifer
- NGUYEN Thanh Lo√Øc

## External libraries needed

All these librairies should be installed in order for the full code to run:

- numpy
- matplotlib
- scipy
- pickle
- pandas
- seaborn
- [surprise](http://surpriselib.com/)
- Jupyter Notebook


## Prerequisites


* Download the dataset from the [crowdAI challenge](https://www.crowdai.org/challenges/epfl-ml-recommender-system/dataset_files) website (if not already present) and place them in the `data/` folder w.r.t to the root folder.
Create one if it is not present. 
**Important:** The sample submission file should be renamed as `sampleSubmission.csv` and the name of the train data should be `47b05e70-6076-44e8-96da-2530dc2187de_data_train.csv` (original name of the train data)

* All the models were already computed and saved as pickle files in order to save some computation time in stored into the `models` and `models_final` folders as pickle files.
* If the files are not present, they need to generated by running changing the `generation_model` and `generation_final_models` parameters to `True` at the beginning of the `run.ipynb` notebook.
       

## Description of folder and files

* The `data/` folder contains the training data `47b05e70-6076-44e8-96da-2530dc2187de_data_train.csv` and the dummy submission `sampleSubmission.csv`
* The `models` folders contains all the predictions for a testset and trained on a 90/10 split. That folder also contains the splitted trainset, testset and corresponding labels.
* The `models_final` folders contains all the predictions for crowdAI for each model and trained on the full dataset.
* `run.ipynb` contains the jupyter notebook that generates the submission file.
* `ALS.py` contains the implementation of the Alternating Least Squares model
* `CV.py` contains a cross-validation function for the ALS and the SGD
* `data_exploration.py` contains function needed to do data exploration
* `grid_search.py` contains an implementation of the grid search in order to find the best hyperparemeter for SGD and ALS
* `helper.py` contains various helpers functions
* `learning.py` contains a function used to train and generate predictions for all our models
* `loading_models.py` contains a function to load all the models saved as pickle files
* `SGD.py` contains an implementation of the Stochastic Gradient Descent model
* `simple_models` contains all the means and median based model
* `surprise_models.py` contains all the models based on the surprise library along with helpers functions 
* `Visualitation.py` contains a function to help display cross validation result


## Creating a csv submission for crowdAI

In order to create the submission, you have to:
* Run the `run.ipynb` file entierly, the submission will be generated as `final_submission.csv`. You can use the "Restart and run all" option of Jupyter Notebook

* If you get an error saying that the models were not found, you can generate them again by changing the `generation_model` and `generation_final_models` parameters to `True` at the beginning of the `run.ipynb` notebook. 
    
    




